ğŸ•¸ï¸ Micro Scraper API

A lightweight web scraping API built with Node.js, Express, and Puppeteer.
This API allows users to scrape the <title>, <meta name="description">, and first <h1> element from any given webpage URL.

ğŸš€ Features

GET /api/scrape?url=... â€” main endpoint for scraping.

Extracts:

Page Title

Meta Description

First H1 tag

Automatic timeout after 20 seconds (prevents long-running scrapes).

Custom User-Agent to simulate a real Chrome browser.

Error handling with appropriate HTTP response codes.

Simple JSON output, ready for integration with other services.

âš™ï¸ Tech Stack
Component	Description
Node.js	JavaScript runtime
Express	Web framework for API routing
Puppeteer	Headless browser for scraping
Nodemon	Auto-restart tool for development
ğŸ“‚ Project Structure
micro-scraper-api/
â”œâ”€ index.js                # Main Express server
â”œâ”€ scraperService.js       # Puppeteer logic and utility functions
â”œâ”€ package.json            # Dependencies and scripts
â””â”€ README.md               # Project documentation

ğŸ§© Installation

Clone this repository

git clone https://github.com/Aul-rhmn/micro-scraper.git
cd micro-scraper-api


Install dependencies

npm install


Run the server

npm run dev


or for production:

npm start


API will run on:

http://localhost:3000

ğŸ” API Usage
Endpoint
GET /api/scrape?url=<target_url>

Example Request
curl "http://localhost:3000/api/scrape?url=https://example.com"

Example Response
{
  "title": "Example Domain",
  "metaDescription": "This domain is for use in illustrative examples in documents.",
  "h1": "Example Domain",
  "status": 200
}

âš ï¸ Error Responses
Status Code	Description	Example
400	Invalid or missing URL	{ "error": "Invalid URL" }
504	Timeout (page took too long to load)	{ "error": "Timeout" }
500	Internal or scraping failure	{ "error": "Scraping failed (e.g., DNS or connection issue)" }
ğŸ§  How It Works

Validates the input URL using Nodeâ€™s URL object.

Launches a headless Chromium browser via Puppeteer.

Waits until the page finishes loading (networkidle0).

Extracts:

<title> text

<meta name="description"> content

First <h1> tag text

Returns results as JSON.

Automatically cancels if scraping exceeds 20 seconds.

ğŸ“œ Scripts
Command	Description
npm start	Run the server (production mode)
npm run dev	Run with Nodemon (development mode)
ğŸ“„ License

This project is licensed
